---
title: "SenatorTwitterDB"
author: "Melissa Michels"
date: "4/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(stm)
library(rquery)
library(reshape2)
```

# Load the data that we scraped
```{r}
load("tweetsMidAll.Rda")
load("tweetsEndAll.Rda")
load("tweetsBegAll.Rda")
```

# Combine all tweets into one dataframe
```{r merging data}
all_tweets <- rbind(tweets_beg_all, tweets_mid_all, tweets_end_all)
```

# Create the senator personal information tibble
```{r personal information tibble}
load("senatorDataDF.Rda")
senator_personal_information_df <- as.data.frame(senatorsdf)
head(senator_personal_information_df)

senator_rename <- c("State", "Name", "Username")
colnames(senator_personal_information_df) <- senator_rename

```

# Create the tweet information tibble
```{r tweet info tibble}
tweet_information <- all_tweets %>% select(screen_name, 
                                           status_id, 
                                           text, 
                                           created_at, 
                                           is_retweet, 
                                           favorite_count, 
                                           retweet_count, 
                                           hashtags)
# cleaning up is_retweet and hashtags column
tweet_information$is_retweet <- as.integer(as.logical(tweet_information$is_retweet))
getHashTags <- function(x) {
  paste(unlist(x), collapse=' ')
}
result <- lapply(tweet_information$hashtags, getHashTags)
result <- unlist(result)

tweet_information$hashtags <- result

tweet_information_df <- data.frame(tweet_information)

tweet_information_names <- c("Username", 
                             "Status_Id",  
                             "Text", 
                             "Created_at", 
                             "Is_Retweet",
                             "Favorite_count", 
                             "Retweet_count", 
                             "Hashtag")
colnames(tweet_information_df) <- tweet_information_names

```



# Create the tweet meta data tibble
```{r meta data tibble}
tweet_meta <- all_tweets %>% select(user_id,
                                    status_id,
                                    screen_name,
                                    source,
                                    reply_to_screen_name,
                                    lang,
                                    quoted_text,
                                    quoted_source,
                                    status_url,
                                    description,
                                    followers_count,
                                    friends_count,
                                    statuses_count,
                                    verified,
                                    profile_url)

# cleaning up verified column

tweet_meta$verified <- as.integer(as.logical(tweet_meta$verified))

tweet_meta_df <- data.frame(tweet_meta)

tweet_meta_df_names <- c("UserId", "Status_Id", "Username" , "Source", "Reply_to_screen_name", "Lang",
            "Quoted_text", "Quoted_source", "Status_url","Description", "Followers_count", "Friends_count",
            "Statuses_count", "Verified", "Profile_url")
colnames(tweet_meta_df) <- tweet_meta_df_names


```

# Create the EAAP (Emotional Analysis of American Politics) Database
```{r database}
fn <- "eaap.sqlite"
#Check its existence
if (file.exists(fn)) {
  #Delete file if it exists
  file.remove(fn) 
}

library("RSQLite")
db<-dbConnect(SQLite(),dbname="eaap.sqlite")
summary(db)

# Create Senator table 
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Senators_PI ( State TEXT, Name TEXT, Username TEXT PRIMARY KEY)")
dbWriteTable(conn = db, name = "Senators_PI", value = senator_personal_information_df, row.names = F, append = T)
#dbReadTable(db, "Senators_PI")

# Create Tweet table 
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Tweets (Username TEXT, 
            Status_Id TEXT, 
            Text TEXT,
            Created_at TEXT,
            Is_Retweet INTEGER,
            Favorite_count INTEGER, 
            Retweet_count INTEGER,
            Hashtag TEXT, 
            PRIMARY KEY (Username, Status_Id))")
dbWriteTable(conn = db, name = "Tweets", value = tweet_information_df, row.names = F, append = T)
#dbReadTable(db, "Tweets")

# Additional data
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Tweet_Metadata (UserID INTEGER,
            Status_Id TEXT PRIMARY KEY, 
            Username TEXT, 
            Source TEXT,
            Reply_to_screen_name TEXT,
            Lang TEXT,
            Quoted_text TEXT,
            Quoted_source TEXT,
            Status_url TEXT,
            Description TEXT, 
            Followers_count INTEGER,
            Friends_count INTEGER,
            Statuses_count INTEGER, 
            Verified INT,
            Profile_url TEXT)")
dbWriteTable(conn = db, name = "Tweet_Metadata", value = tweet_meta_df, row.names = F, append = T)
#dbReadTable(db, "Tweet_Metadata")

#dbListTables(db)

```

Word Cloud
```{r wordcloud}

all_tweets <- dbGetQuery(db, "SELECT *  
                      FROM Tweets")


tweet_text <- tibble(text = all_tweets$Text)

fillerwords <- c("t.co", "https", "amp", "1", "2", "it's")
fillerwordstable <- tibble("word" = fillerwords)

tweet_text %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% summarize(count = n()) %>%
  anti_join(stop_words) %>% # removing stop words
  anti_join(fillerwordstable, by = "word") %>%
  with(wordcloud(word, count, use.r.layout=FALSE, max.words = 150, random.order = FALSE, 
                 colors = brewer.pal(6, "Dark2"), scale=c(3,.1)))
```
General Sentiment Analysis
```{r}
nrc = sentiments %>% filter(lexicon=="nrc")
bing = sentiments %>% filter(lexicon=="bing")

wordCounts <- tweet_text %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% 
  summarize(count=n())

wordCounts %>% 
  inner_join(nrc) %>%
  group_by(sentiment) %>%
  summarize(score = sum(count)) %>%
  mutate(share = score/sum(score) * 100) %>%
  ggplot(aes(x=sentiment, y=share, fill = sentiment)) +
  geom_bar(stat="identity") + 
  labs(title="Sentiment in US Senator Tweets", subtitle="Sentiment as share of sentiment words from last month's tweets.")

wordCounts %>% 
  inner_join(bing) %>%
  group_by(sentiment) %>%
  summarize(score = sum(count)) %>%
  mutate(share = score/sum(score) * 100) %>%
  ggplot(aes(x=sentiment, y=share, fill = sentiment)) +
  geom_bar(stat="identity") + 
  labs(title="Sentiment in US Senator Tweets", subtitle="Positive and negative sentiment as share of sentiment words from last month's tweets.")
```


ngrams
```{r}
fillerwords <- c("t.co", "https", "amp")
fillerwordstable <- tibble("word" = fillerwords)

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=4) %>%
  group_by(word) %>%
  filter(n()>35) %>%
  ggplot() + 
  geom_bar(fill="lightsalmon2") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=4")

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=5) %>%
  group_by(word) %>%
  filter(n()>12) %>%
  ggplot() + 
  geom_bar(fill="cyan3") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=5")

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=3) %>%
  group_by(word) %>%
  filter(n()>100) %>%
  ggplot() + 
  geom_bar(fill="darkorchid") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=3")
```


Hashtag Analysis
```{r}
hashtags <- tibble(text = all_tweets$Hashtag)

hashtagCounts <- hashtags %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% summarize(count = n()) %>%
  anti_join(stop_words) %>%# removing stop words
  arrange(desc(count)) %>%
  filter(word != "na")

top10 <- top_n(hashtagCounts, 10)

hashtagCounts

top10 %>% 
  ggplot() + 
  geom_bar(fill="darkolivegreen4", aes(x=word, y=count),stat="identity") + 
  coord_flip()


hashtagCounts %>%
  with(wordcloud(word, count, use.r.layout=FALSE, max.words = 150, random.order = FALSE, 
                 colors = brewer.pal(8, "Dark2"), scale=c(3,.4)))
```



Sentiment by Party
```{r}
ggplot(all_tweets, aes(created_at, fill="cadetblue3")) +
  geom_histogram() + 
  labs(title="Distribution of Tweets")
```

