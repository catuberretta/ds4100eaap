---
title: "Sentiment Analysis in American Politics - Twitter Data from March"
author: "Melissa Michels, Fiona Tran, Catu Barretta"
date: "4/8/2019"
output: html_document
---

Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(stm)
library(rquery)
library(reshape2)
```

## Part 1. Data Collection

Loading data pulled using the rtweet API
```{r}
load("tweetsMidAll.Rda")
load("tweetsEndAll.Rda")
load("tweetsBegAll.Rda")
```
We aimed for all members of our group to become familiar with the rtweet API. We split the 100 senators among the three of us to obtain the data. This allowed us to minimize time spent obtaining the data and allowed for more efficient data collection. We each created a dataframe and saved it as a .Rda object. The code above loads the dataframes that we individually created.

Combine all tweets into one dataframe
```{r merging data}
all_tweets <- rbind(tweets_beg_all, tweets_mid_all, tweets_end_all)
```

## Part 2. Data Cleaning

Create the senator personal information tibble
```{r personal information tibble}
load("senatorDataDF.Rda")
senator_personal_information_df <- as.data.frame(senatorsdf)
head(senator_personal_information_df)

senator_rename <- c("State", "Name", "Username")
colnames(senator_personal_information_df) <- senator_rename
```

Create the tweet information tibble
```{r tweet info tibble}
tweet_information <- all_tweets %>% select(screen_name, 
                                           status_id, 
                                           text, 
                                           created_at, 
                                           is_retweet, 
                                           favorite_count, 
                                           retweet_count, 
                                           hashtags)
# cleaning up is_retweet, hashtags column, and dates
tweet_information$is_retweet <- as.integer(as.logical(tweet_information$is_retweet))
getHashTags <- function(x) {
  paste(unlist(x), collapse=' ')
}
result <- lapply(tweet_information$hashtags, getHashTags)
result <- unlist(result)

tweet_information$hashtags <- result

tweet_information$created_at <- as.character(tweet_information$created_at)

tweet_information_df <- data.frame(tweet_information)

tweet_information_names <- c("Username", 
                             "Status_Id",  
                             "Text", 
                             "Created_at", 
                             "Is_Retweet",
                             "Favorite_count", 
                             "Retweet_count", 
                             "Hashtag")
colnames(tweet_information_df) <- tweet_information_names

```


Create the tweet meta data tibble
```{r meta data tibble}
tweet_meta <- all_tweets %>% select(user_id,
                                    status_id,
                                    screen_name,
                                    source,
                                    reply_to_screen_name,
                                    lang,
                                    quoted_text,
                                    quoted_source,
                                    status_url,
                                    description,
                                    followers_count,
                                    friends_count,
                                    statuses_count,
                                    verified,
                                    profile_url)

# cleaning up verified column

tweet_meta$verified <- as.integer(as.logical(tweet_meta$verified))

tweet_meta_df <- data.frame(tweet_meta)

tweet_meta_df_names <- c("UserId", "Status_Id", "Username" , "Source", "Reply_to_screen_name", "Lang",
            "Quoted_text", "Quoted_source", "Status_url","Description", "Followers_count", "Friends_count",
            "Statuses_count", "Verified", "Profile_url")
colnames(tweet_meta_df) <- tweet_meta_df_names
```

## Part 3. Exploratory Data Analysis

Senator Details for Number of Followers, Avg Retweets, and Avg Favorites
```{r}
# Average number of retweets/favorites per tweet
info1 <- tweet_information_df %>% group_by(Username) %>% summarize(avgretweets = mean(Retweet_count),
                                                          avgfavorites = mean(Favorite_count))
# Number of followers
info2 <- tweet_meta_df %>% group_by(Username) %>% summarise(numfollowers = max(Followers_count))
info2

activityindexvaluesdf <- inner_join(info1, info2, by="Username")
head(activityindexvaluesdf)
```

Relationship between number of followers and average retweets per tweet
```{r}
ggplot(activityindexvaluesdf, aes(x=numfollowers, y=avgretweets)) + 
  geom_point() +
  geom_smooth() + 
  labs(title="Number of followers vs. Average Retweets")
```

Relationship between number of followers and average favorites per tweet
```{r}
ggplot(activityindexvaluesdf, aes(x=numfollowers, y=avgfavorites)) + 
  geom_point() +
  geom_smooth() + 
  labs(title="Number of followers vs. Average Favorites")
```
```{r}
ggplot(activityindexvaluesdf, aes(x=avgretweets, y=avgfavorites)) + 
  geom_point() +
  geom_smooth() + 
  labs(title="Average Favorites vs. Average Retweets")
```

As displayed above, the relationship between a Senator's average favorites and average retweets is stronger than the relationship between reweets/favorites and their number of followers. Because we would like to measure a Senator's engagement on the social media platform, average retweets and average favorites will be weighted higher in calculating their scores.

We will also normalize the data using mix/max normalization - by mapping all values between 0 and 1. This will allow for standardized comparisons.

Calculating the Activity Index
```{r}
normalize <- function(x) {
    ((x - min(x)) / (max(x) - min(x)))
}

# First, normalize the the date
activityindexvaluesdf[2:4] <- as.data.frame(lapply(activityindexvaluesdf[2:4], normalize))

activityindexdf <- activityindexvaluesdf %>% group_by(Username) %>% summarise(activityindex = sum((.375*avgretweets),
                                                                             (.375*avgfavorites),
                                                                             (.25*numfollowers)))
activityindexdf %>% arrange(desc(activityindex))
```
A Senator's activity index is calculated by observing three factors of their online twitter presence. 25% of their score is comprised of the number of followers for that senator. 37.5% is calculated by their average number of rewteets per tweet and 37.5% is comprised of the average number of favorites they receive per tweet.

So who are the most active senators?
```{r}
activityindexdf %>% arrange(desc(activityindex))

activityindexdf %>% top_n(10) %>%
  ggplot() + 
  geom_point(fill="lightsalmon2", size=5, shape=21) + 
  aes(x= Username, y=activityindex) + 
  coord_flip() + 
  labs(title="Top 10 Most Active Senators")
```

Adding Activity Index to the Senator Personal Information Dataframe
```{r}
senator_personal_information_df <- left_join(senator_personal_information_df, activityindexdf, by="Username")
```

## Part 4. Database Creation

Creating the EAAP (Emotional Analysis of American Politics) Database
```{r database}
fn <- "eaap.sqlite"
#Check its existence
if (file.exists(fn)) {
  #Delete file if it exists
  file.remove(fn) 
}

library("RSQLite")
db<-dbConnect(SQLite(),dbname="eaap.sqlite")
summary(db)

# Create Senator table 
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Senators_PI ( State TEXT, 
            Name TEXT, 
            Username TEXT PRIMARY KEY,
            activityindex REAL)")
dbWriteTable(conn = db, name = "Senators_PI", value = senator_personal_information_df, row.names = F, append = T)
#dbReadTable(db, "Senators_PI")

# Create Tweet table 
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Tweets (Username TEXT, 
            Status_Id TEXT, 
            Text TEXT,
            Created_at TEXT,
            Is_Retweet INTEGER,
            Favorite_count INTEGER, 
            Retweet_count INTEGER,
            Hashtag TEXT, 
            PRIMARY KEY (Username, Status_Id))")
dbWriteTable(conn = db, name = "Tweets", value = tweet_information_df, row.names = F, append = T)
#dbReadTable(db, "Tweets")

# Additional data
dbSendQuery(conn=db, "CREATE TABLE IF NOT EXISTS Tweet_Metadata (UserID INTEGER,
            Status_Id TEXT PRIMARY KEY, 
            Username TEXT, 
            Source TEXT,
            Reply_to_screen_name TEXT,
            Lang TEXT,
            Quoted_text TEXT,
            Quoted_source TEXT,
            Status_url TEXT,
            Description TEXT, 
            Followers_count INTEGER,
            Friends_count INTEGER,
            Statuses_count INTEGER, 
            Verified INT,
            Profile_url TEXT)")
dbWriteTable(conn = db, name = "Tweet_Metadata", value = tweet_meta_df, row.names = F, append = T)
#dbReadTable(db, "Tweet_Metadata")

#dbListTables(db)

```

## Part 5. Data Analysis

Word Cloud
```{r wordcloud}

all_tweets <- dbGetQuery(db, "SELECT *  
                      FROM Tweets")


tweet_text <- tibble(text = all_tweets$Text)

fillerwords <- c("t.co", "https", "amp", "1", "2", "it's")
fillerwordstable <- tibble("word" = fillerwords)

tweet_text %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% summarize(count = n()) %>%
  anti_join(stop_words) %>% # removing stop words
  anti_join(fillerwordstable, by = "word") %>%
  with(wordcloud(word, count, use.r.layout=FALSE, max.words = 150, random.order = FALSE, 
                 colors = brewer.pal(6, "Dark2"), scale=c(3,.1)))
```
General Sentiment Analysis
```{r}
nrc = sentiments %>% filter(lexicon=="nrc")
bing = sentiments %>% filter(lexicon=="bing")

wordCounts <- tweet_text %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% 
  summarize(count=n())

wordCounts %>% 
  inner_join(nrc) %>%
  group_by(sentiment) %>%
  summarize(score = sum(count)) %>%
  mutate(share = score/sum(score) * 100) %>%
  ggplot(aes(x=sentiment, y=share, fill = sentiment)) +
  geom_bar(stat="identity") + 
  labs(title="Sentiment in US Senator Tweets", subtitle="Sentiment as share of sentiment words from last month's tweets.")

wordCounts %>% 
  inner_join(bing) %>%
  group_by(sentiment) %>%
  summarize(score = sum(count)) %>%
  mutate(share = score/sum(score) * 100) %>%
  ggplot(aes(x=sentiment, y=share, fill = sentiment)) +
  geom_bar(stat="identity") + 
  labs(title="Sentiment in US Senator Tweets", subtitle="Positive and negative sentiment as share of sentiment words from last month's tweets.")
```


ngrams
```{r}
fillerwords <- c("t.co", "https", "amp")
fillerwordstable <- tibble("word" = fillerwords)

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=4) %>%
  group_by(word) %>%
  filter(n()>35) %>%
  ggplot() + 
  geom_bar(fill="lightsalmon2") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=4")

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=5) %>%
  group_by(word) %>%
  filter(n()>12) %>%
  ggplot() + 
  geom_bar(fill="cyan3") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=5")

tweet_text %>%
  unnest_tokens(word,text,token="ngrams",n=3) %>%
  group_by(word) %>%
  filter(n()>100) %>%
  ggplot() + 
  geom_bar(fill="darkorchid") + 
  aes(x=word) + 
  coord_flip() + 
  labs(title="NGram for all Tweets", subtitle="n=3")
```


Hashtag Analysis
```{r}
hashtags <- tibble(text = all_tweets$Hashtag)

hashtagCounts <- hashtags %>%
  unnest_tokens(word, text) %>%
  group_by(word) %>% summarize(count = n()) %>%
  anti_join(stop_words) %>%# removing stop words
  arrange(desc(count)) %>%
  filter(word != "na")

top10 <- top_n(hashtagCounts, 10)

hashtagCounts

top10 %>% 
  ggplot() + 
  geom_bar(fill="darkolivegreen4", aes(x=word, y=count),stat="identity") + 
  coord_flip()


hashtagCounts %>%
  with(wordcloud(word, count, use.r.layout=FALSE, max.words = 150, random.order = FALSE, 
                 colors = brewer.pal(8, "Dark2"), scale=c(3,.4)))
```

Distribution of Tweets: Based on the date that they were created.
```{r}
dates <- as.Date(all_tweets$Created_at)

ggplot(all_tweets, aes(dates, fill="cadetblue3")) +
  geom_histogram() + 
  labs(title="Distribution of Tweets")
```
